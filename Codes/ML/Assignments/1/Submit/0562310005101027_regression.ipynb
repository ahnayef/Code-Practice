{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246fb3f",
   "metadata": {},
   "source": [
    "### Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e39c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    \n",
    "    if isinstance(value, (int, float)):\n",
    "        return value\n",
    "    \n",
    "    value = str(value).strip()\n",
    "    \n",
    "    if value.lower() in ['nan', 'null', '?', '', 'none', 'na']:\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        numeric_match = re.search(r'[-+]?\\d*\\.?\\d+', value)\n",
    "        if numeric_match:\n",
    "            return float(numeric_match.group())\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def handle_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = ((df[column] < lower_bound) | (df[column] > upper_bound)).sum()\n",
    "    \n",
    "    if outliers > 0:\n",
    "        df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "        df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df.describe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548b59c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dd1c1ca",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fca9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['StudentID']\n",
    "\n",
    "all_cols = ['Age', 'StudyTimeWeekly', 'Absences', 'ParentalEducation', 'GPA', 'Tutoring', 'ParentalSupport', 'Extracurricular', \"Sports\", 'Gender', 'Ethnicity', 'Music', 'Volunteering', 'GradeClass']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c483252",
   "metadata": {},
   "source": [
    "### Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb865e50",
   "metadata": {},
   "source": [
    "### Removing Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333a6d7b",
   "metadata": {},
   "source": [
    "### Making numeric columns truly numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69aa869",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_cols:\n",
    "    df[col] = df[col].apply(clean_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8d09a",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    " - We will fill missing values in numeric columns with the median of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f5df76",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "df[all_cols] = numeric_imputer.fit_transform(df[all_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8c733",
   "metadata": {},
   "source": [
    "### Removing outliers, using IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Age', 'StudyTimeWeekly', 'Absences', 'GPA']:\n",
    "    df = handle_outliers(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3293508",
   "metadata": {},
   "source": [
    "### Handling unrealistic combinations\n",
    "1. Students with very low study time but very high GPA.\n",
    "2. Students with very high study time but very low GPA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd950ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "unrealistic = ((df['StudyTimeWeekly'] < 1) & (df['GPA'] > 3.5)).sum()\n",
    "if unrealistic > 0:\n",
    "    mask = (df['StudyTimeWeekly'] < 1) & (df['GPA'] > 3.5)\n",
    "    df.loc[mask, 'StudyTimeWeekly'] = df['StudyTimeWeekly'].median()\n",
    "\n",
    "unrealistic = ((df['StudyTimeWeekly'] > 15) & (df['GPA'] < 2.0)).sum()\n",
    "if unrealistic > 0:\n",
    "    mask = (df['StudyTimeWeekly'] > 15) & (df['GPA'] < 2.0)\n",
    "    df.loc[mask, 'StudyTimeWeekly'] = df['StudyTimeWeekly'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb39bf6",
   "metadata": {},
   "source": [
    "### Handling negetive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in  all_cols:\n",
    "    neg_values = (df[col] < 0).sum()\n",
    "    if neg_values > 0:\n",
    "        df[col] = df[col].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1e4c0",
   "metadata": {},
   "source": [
    "### Type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in all_cols:\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353c019",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['GPA'])\n",
    "Y = df['GPA']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
